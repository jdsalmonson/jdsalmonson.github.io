---
layout: post
title: Programming Robots Study Group
categories: [Robotics]
---

![My PRSG2 robot](/assets/images/prsg2.png)
My PRSG2 robot

From 2015 to 2018 I was an active participant of the [Programming Robots Study Group](https://programmingrobotsstudygroup.github.io/) through the [Robot Garden](https://www.robotgarden.org/) Maker-space.  Our charter was to learn about [ROS](https://ros.org/) and build robots that utilize it.  We built two robots: the PRSG1 and PRSG2 shown above.  Both were run by battery operated Raspberry Pi computers with an Arduino "hat" that interfaced with the sensors, motors, and encoders.

### PRSG 1

The PRSG 1 is not only the first robot I've ever built, but the first electronics project I've undertaken.  

<table>
  <tr>
  <td>
    <a href="/assets/images/prsg1_1.png" ><img src="/assets/images/prsg1_1.png" width="300"/></a>
  </td>
  <td>
    <a href="/assets/images/prsg1_2.png" ><img src="/assets/images/prsg1_2.png" width="300"/></a>
  </td>
  </tr>
  <tr>
  <td>
    <a href="/assets/images/prsg1_3.png" ><img src="/assets/images/prsg1_3.png" width="300"/></a>
  </td>
  <td>
    <a href="/assets/images/prsg1_detail.png" ><img src="/assets/images/prsg1_detail.png" width="300"/></a>
  </td>
  </tr>
</table>

### PRSG 2

The next version of our robot was based on a [custom design](https://github.com/ProgrammingRobotsStudyGroup/Designs-And-Notes/wiki/REV2-Specification---Purpose---Objective) by study group member [Darron Nielsen](https://github.com/microsat).  The chassis is a 23 cm diameter circular platter supported by two servo motors with internal encoders, and two castors.  This enabled nimble maneuverability for swarm interactions or group dance (see the quadrille below).  A Raspberry Pi 3 running Ubuntu Linux ran ROS an interfaced with the Pololu A* 32u4 Pi bridge via an I2C (in my case; others used a serial interface).  The A* ran the servos via an H-bridge as well the IR sensors and their swivel servos.

![PRSG2 group photo](/assets/images/prsg2016_group_photo.png)
There is always one idiot who forgets to bring his robot for picture day (me: upper left)

My [PRSG fork](https://github.com/jdsalmonson/prsg2_robot)

My [quadrille ROS node](https://github.com/jdsalmonson/quadrille/blob/master/src/quadrille.py) using the ROS Twist message to dance to Tchaikovsky's Nutcracker.

<iframe width="800" height="600"
src="https://www.youtube.com/embed/3CmUX405ft8"
frameborder="0"
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
allowfullscreen></iframe>

Or try this:

<div align="left">
      <a href="https://www.youtube.com/watch?v=3CmUX405ft8">
         <img src="https://img.youtube.com/vi/3CmUX405ft8/0.jpg" style="width:100%;">
      </a>
</div>

My PRSG 2 robot moves around the kitchen while infrared sensors swivel on their servos, scanning the environment.
<iframe width="800" height="600"
src="https://www.youtube.com/embed/UOTSG5NKjkM"
frameborder="0"
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
allowfullscreen></iframe>

### Simulation

The PRSG robot is well suited for basic, plan-view 2D simulation; navigating and sensing its environment and nearby robots.  While I did create a [Gazebo ROS node](https://github.com/jdsalmonson/prsg2_gazebo) that rendered a 3D SDF model of PRSG in a 3D world, I found that to be unwieldy and overkill for these goals.  The [STDR](http://wiki.ros.org/stdr_simulator) (simple 2D robot) simulator turned out to be a much simpler solution.  STDR allows for a relatively simple robot specification and the world map is a simple black and white image where the black pixel values are interpreted as walls and barriers in the environment.  Also, multiple robots can be included in the environment as shown in the image below from a simulation.

![stdr PRSG robots](/assets/images/stdr_4prsg_bots.png)
STDR simulation with 4 PRSG2 robots.

While STDR allows sensors to be attached to the robot, they have to be fixed to the robot body.  In order to properly model my IR sensor's ability to swivel on their servo motors, I had to create my own [fork of the STDR ROS node](https://github.com/jdsalmonson/stdr_simulator) that added sensor pose read/write services.  I issued a pull request for these changes in 2017, but the package does not appear to be actively supported.  My [STDR PRSG ROS node](https://github.com/jdsalmonson/stdr_prsg2) that employs these updates and worked very well and was able to navigate a virtual room, collecting odometry as well as servo and IR sensor data into a ROS bag log file.
